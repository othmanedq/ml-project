# NBA-Rating Machine Learning Project ‚Äî Players

## üìä Data, Methods & Sources (Players)

| Aspect | Description |
|--------|-------------|
| **Data type** | *Tabular sports data* sur tous les joueurs NBA, saisons **1999 ‚Üí 2023**.  
‚Ä¢ **Box-scores par match** (PTS, REB, AST, ¬± ‚Ä¶)  
‚Ä¢ **Caract√©ristiques physiques** (taille, poids, BMI, √¢ge, poste)  
‚Ä¢ **Stats d√©riv√©es** par saison : `min_per_game`, per-36, efficacit√© au tir (eFG %, TS %), Estimated Shot Value `esv_mean`  
‚Ä¢ **Cible** : `score_100`, rating unidimensionnel recentr√© (Œº = 50, œÉ = 25) |
| **Sources & API endpoints** | [`nba_api`](https://github.com/swar/nba_api) ‚Äì NBA Stats REST  
‚Ä¢ `LeagueGameLog` ‚Üí box-scores  
‚Ä¢ `CommonTeamRoster` ‚Üí physiques & position  
‚Ä¢ `LeagueDashPlayerStats` ‚Üí shot profile (ESV)  
Automatisation dans **`scripts/collect_raw.py`** ; caches parquet sous `nba_rating/data/raw/`. |
| **Data preparation** | **`prepare_curated.py`** & **`feature_engineering.py`**  
1. Agr√©gation logs ‚Üí moyennes saison/joueur  
2. Fusion physiques, calcul BMI & disponibilit√© (`gp/82`)  
3. Ajout per-36 & features d‚Äôefficacit√©  
4. Sortie `player_season_YYYY-YY.parquet` dans `data/curated/`. |
| **Purpose** | ‚Ä¢ Construire une **r√©f√©rence de rating** (`score_100`) comparable entre √©poques  
‚Ä¢ Entra√Æner un mod√®le pr√©disant le **score saison suivante** (`note_n+1`) pour d√©tecter breakout/decline  
‚Ä¢ Alimenter un futur dashboard Streamlit pour scouting & analytics fans. |

---

## ü§ñ Machine-Learning Methods & Rationale (Players)

| Mod√®le | Pourquoi ce choix ? |
|--------|---------------------|
| **Ridge Regression** | Baseline lin√©aire r√©gularis√©e (L2) : interpr√©table, tr√®s rapide, souvent proche du RMSE mini apr√®s normalisation Z-score. |
| **HistGradientBoostingRegressor** | Boosting √† histogrammes (scikit-learn) : capture non-lin√©arit√©s & interactions, tuning mod√©r√©, robuste sur grandes tables. |
| **LightGBM** | GBDT ultra-rapide (CPU/GPU), g√®re nativement missing values & cat√©gories, ‚âà 5 % plus pr√©cis que HGB pour un co√ªt calcul raisonnable. |
| **MLPRegressor** | R√©seau feed-forward (64-128-64) : apprend des patterns non lin√©aires fins ; gagne ~0.5 % RMSE sur nos donn√©es pour un temps < 5 s. |
| **Stacking final** | Ensemble Ridge + HGB + LightGBM (+ MLP) avec meta-Ridge : combine lin√©aire & non-lin√©aire, ~-2 % RMSE suppl√©mentaire en CV. |

> **Crit√®res de s√©lection** : performance (RMSE / R¬≤, 5-fold CV), robustesse (variance entre folds), temps d‚Äôentra√Ænement/pr√©diction (CI-friendly), interpr√©tabilit√© (coeffs Ridge, permutation importance HGB/LGBM).


Nom des participants : Louis ALLIO ‚Äî Noa KASSABI ‚Äî Othmane EDDAQQAQ